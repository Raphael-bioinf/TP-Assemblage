{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-198b55d68f86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnoeuds_entree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m \u001b[0mnoeuds_entree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_starting_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sink_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "#!/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "#    This program is free software: you can redistribute it and/or modify\n",
    "#    it under the terms of the GNU General Public License as published by\n",
    "#    the Free Software Foundation, either version 3 of the License, or\n",
    "#    (at your option) any later version.\n",
    "#    This program is distributed in the hope that it will be useful,\n",
    "#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#    GNU General Public License for more details.\n",
    "#    A copy of the GNU General Public License is available at\n",
    "#    http://www.gnu.org/licenses/gpl-3.0.html\n",
    "\n",
    "\"\"\"Perform assembly based on debruijn graph.\"\"\"\n",
    "\n",
    "import scipy\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "from operator import itemgetter\n",
    "import random\n",
    "random.seed(9001)\n",
    "from random import randint\n",
    "import statistics\n",
    "\n",
    "__author__ = \"Raphael Bodin\"\n",
    "__copyright__ = \"Universite Paris Diderot\"\n",
    "__credits__ = [\"Raphael Bodin\"]\n",
    "__license__ = \"GPL\"\n",
    "__version__ = \"1.0.0\"\n",
    "__maintainer__ = \"Raphael Bodin\"\n",
    "__email__ = \"raphael.bodin@etu.univ-nantes.fr\"\n",
    "__status__ = \"Developpement\"\n",
    "\n",
    "def isfile(path):\n",
    "    \"\"\"Check if path is an existing file.\n",
    "      :Parameters:\n",
    "          path: Path to the file\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(path):\n",
    "        if os.path.isdir(path):\n",
    "            msg = \"{0} is a directory\".format(path)\n",
    "        else:\n",
    "            msg = \"{0} does not exist.\".format(path)\n",
    "        raise argparse.ArgumentTypeError(msg)\n",
    "    return path\n",
    "\n",
    "\n",
    "def get_arguments():\n",
    "    \"\"\"Retrieves the arguments of the program.\n",
    "      Returns: An object that contains the arguments\n",
    "    \"\"\"\n",
    "    # Parsing arguments\n",
    "    parser = argparse.ArgumentParser(description=__doc__, usage=\n",
    "                                     \"{0} -h\"\n",
    "                                     .format(sys.argv[0]))\n",
    "    parser.add_argument('-i', dest='fastq_file', type=isfile,\n",
    "                        required=True, help=\"Fastq file\")\n",
    "    parser.add_argument('-k', dest='kmer_size', type=int,\n",
    "                        default=21, help=\"K-mer size (default 21)\")\n",
    "    parser.add_argument('-o', dest='output_file', type=str,\n",
    "                        default=os.curdir + os.sep + \"contigs.fasta\",\n",
    "                        help=\"Output contigs in fasta file\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "#==============================================================\n",
    "# Main program\n",
    "#==============================================================\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "import scipy\n",
    "import os\n",
    "import statistics\n",
    "import argparse\n",
    "#taille_k=21\n",
    "\n",
    "def read_fastq(fastq_file):\n",
    "    with open(fastq_file,\"r\") as fastq:\n",
    "        for line in enumerate(fastq):\n",
    "            yield next(fastq)[:-1]\n",
    "            next(fastq)\n",
    "            next(fastq)\n",
    "            \n",
    "\n",
    "\n",
    "def cut_kmer(seq, taille_k):\n",
    "    #On génère des k-mers de taille désirée à partir d'un read .\n",
    "    for i in range(len(seq)-taille_k+1):\n",
    "        yield seq[i:i+taille_k]\n",
    "        \n",
    "        \n",
    "def build_kmer_dict(fastq_file,taille_k):\n",
    "    \"\"\"Calcule des occurrences des Kmers dans les reads issus du fastq.\n",
    "    \"\"\"\n",
    "    liste_reads = []\n",
    "    for sequence in fastq_file:\n",
    "        liste_reads.append(sequence)\n",
    "    occurrence_kmers = {}\n",
    "    for read in liste_reads:\n",
    "        for kmer in cut_kmer(read, taille_k):\n",
    "            if kmer in occurrence_kmers.keys():\n",
    "                occurrence_kmers[kmer] += 1\n",
    "            else:\n",
    "                occurrence_kmers[kmer] = 1\n",
    "    return occurrence_kmers\n",
    "\n",
    "\n",
    "\n",
    "def build_graph(dict_kmers):\n",
    "    \"\"\"On créé un premier digraph en prenant en compte tout les kmers générés.\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    for kmer, poids in dict_kmers.items():\n",
    "        graph.add_edge(kmer[:-1], kmer[1:], weight=poids)\n",
    "    nx.draw(graph)\n",
    "    return graph\n",
    "\n",
    "#build_kmer_dict(read_fastq(\"data\\eva71_two_reads.fq.\"), taille_kmer)\n",
    "#graph=build_graph(build_kmer_dict(read_fastq(\"data\\eva71_plus_perfect.fq.\"), taille_k))\n",
    "\n",
    "def get_starting_nodes(graph):\n",
    "    \"\"\"Fonction permettant de définir les noeuds d'entrée.\"\"\"\n",
    "    noeuds_entree = []\n",
    "    for noeud in graph.nodes:\n",
    "        if len(list(graph.predecessors(noeud))) == 0:\n",
    "            noeuds_entree.append(noeud)\n",
    "    return noeuds_entree\n",
    "\n",
    "noeuds_entree = get_starting_nodes(graph)\n",
    "                                   \n",
    "def get_sink_nodes(graph):\n",
    "    \"\"\"Fonction permettant de définir les noeuds de sortie.\"\"\"\n",
    "    noeuds_sortie = []\n",
    "    for noeud in graph.nodes:\n",
    "        if len(list(graph.successors(noeud))) == 0:\n",
    "            noeuds_sortie.append(noeud)\n",
    "    return noeuds_sortie\n",
    "                                   \n",
    "noeuds_sortie = get_sink_nodes(graph)\n",
    "                                   \n",
    "def get_contigs(graph, start, end):\n",
    "    \"\"\"Fonction permettant de générer une liste de tuples contenant les contigs avec leur taille.\n",
    "    \"\"\"\n",
    "    contigs = []\n",
    "    for noeud_depart in start:\n",
    "        for noeud_fin in end:\n",
    "            for path in nx.all_simple_paths(graph,source=noeud_depart, target=noeud_fin):\n",
    "                prep_contig = path\n",
    "                contig_ecrit = prep_contig[0]\n",
    "                for i in range(1, len(prep_contig)):\n",
    "                    contig_ecrit += prep_contig[i][-1:]\n",
    "                contigs.append((contig_ecrit, len(contig_ecrit)))\n",
    "    return contigs\n",
    "\n",
    "\n",
    "def fill(text, width=80):\n",
    "    \"\"\"Split text with a line return to respect fasta format\"\"\"\n",
    "    return os.linesep.join(text[i:i+width] for i in range(0, len(text), width))\n",
    "\n",
    "def save_contigs(liste_contigs, nom_fichier):\n",
    "    \"\"\"Cette fonction permet de sauvegarder les contigs dans un fichier FASTA\n",
    "    \"\"\"\n",
    "    with open(nom_fichier, \"w\") as fichier_sortie:\n",
    "        numero = 0\n",
    "        for contigs in liste_contigs:\n",
    "            fichier_sortie.write(\">contig_{0} len={1}\\n\".format(numero, contigs[1]))\n",
    "            fichier_sortie.write(\"{0}\\n\".format(fill(contigs[0])))\n",
    "            numero += 1\n",
    "\n",
    "    \n",
    "\n",
    "#lg_fichier = \"Contigs_\" + str(len(get_contigs(graph,noeuds_entree,noeuds_sortie)))\n",
    "#save_contigs(get_contigs(graph,noeuds_entree,noeuds_sortie), lg_fichier)\n",
    "\n",
    "def std(liste_valeurs):\n",
    "    \"\"\"Calcul l'écart-type de la liste de valeurs\"\"\"\n",
    "    return statistics.stdev(liste_valeurs)\n",
    "\n",
    "\n",
    "def path_average_weight(graph, chemin):\n",
    "    \"\"\"Cette fonction retourne le poids moyen d'un chemin\n",
    "    \"\"\"\n",
    "    poids = 0\n",
    "    nbre_edges = 0\n",
    "    edges = graph.subgraph(chemin).edges(data=True)\n",
    "    #On va récupérer les poids de chaque lien.\n",
    "    for u_value, v_value, e_value in edges:\n",
    "        poids += e_value['weight']\n",
    "        nbre_edges += 1\n",
    "    poids = poids/nbre_edges\n",
    "    return poids\n",
    "\n",
    "def remove_paths(graph, liste_chemins, delete_entry_node=False, delete_sink_node=False):\n",
    "    \"\"\"Fonction permettant de verifier si on enlève ou non les noeuds de départe et de fin pour chaque chemin\n",
    "    Et retourne un graph nettoyé des chemins indésirables\n",
    "    \"\"\"\n",
    "    for chemin in liste_chemins:\n",
    "        if delete_entry_node == False and delete_sink_node == False:\n",
    "            for noeud in chemin[1:-1]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node and delete_sink_node == False:\n",
    "            for noeud in chemin[:-1]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node == False and delete_sink_node:\n",
    "            for noeud in chemin[1:]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node and delete_sink_node:\n",
    "            for noeud in chemin[:]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "    return graph\n",
    "\n",
    "def select_best_path(graph, ensemble_chemins, ensemble_longueurs,poids_moyen, delete_entry_node=False, delete_sink_node=False):\n",
    "    \"\"\"Fonction qui va permettre d'identifier le meilleur chemin selon 3 critères :\n",
    "    - poids le plus élevé\n",
    "    - les chemins les plus long\n",
    "    - on tire une au hasard\n",
    "    Les chemins non conservés sont envoyés à la fonction remove_paths.\n",
    "    \"\"\"\n",
    "    a_retirer = []\n",
    "    taille_max = max(poids_moyen)\n",
    "    chemin_fort_poids = []\n",
    "    #On recherche les chemins qui ont un poids correspondant\n",
    "    #au poids maximum (de préférence un seul ...)\n",
    "    for i in range(len(ensemble_chemins)):\n",
    "        if poids_moyen[i] == taille_max:\n",
    "            chemin_fort_poids.append(ensemble_chemins[i])\n",
    "    #On récupère les chemins à conserver puis on ajoute\n",
    "    #les autres à la liste \"a_retirer\"\n",
    "    for chemin in chemin_fort_poids:\n",
    "        ensemble_chemins.remove(chemin)\n",
    "    a_retirer = ensemble_chemins + a_retirer\n",
    "    #S'il y a plus qu'un chemin qui a le poids maximum on regarde\n",
    "    #la taille de ceux le poids maximum.\n",
    "    if len(chemin_fort_poids) > 1:\n",
    "        longueur_max = max(ensemble_longueurs)\n",
    "        grands_chemins = []\n",
    "        for i in range(len(chemin_fort_poids)):\n",
    "            if ensemble_longueurs[i] == longueur_max:\n",
    "                grands_chemins.append(chemin_fort_poids[i])\n",
    "        #On récupère les chemins à conserver puis on ajoute\n",
    "        #les autres à la liste \"a_retirer\"\n",
    "        for chemin in grands_chemins:\n",
    "            chemin_fort_poids.remove(chemin)\n",
    "        a_retirer = chemin_fort_poids + a_retirer\n",
    "        #S'il y a plusieurs chemins qui ont la taille maximum\n",
    "        #on tire un chemin au hasard parmis ceux ayant le poids\n",
    "        #maximum et la plus grande taille.\n",
    "        if len(grands_chemins) > 1:\n",
    "            random.seed(9001)\n",
    "            choix = random.randint(0, len(grands_chemins))\n",
    "            print(choix)\n",
    "            choix_chemin = grands_chemins[choix]\n",
    "            #On récupère les chemins à conserver puis on ajoute\n",
    "            #les autres à la liste \"a_retirer\"\n",
    "            grands_chemins.remove(choix_chemin[0])\n",
    "            a_retirer = grands_chemins + a_retirer\n",
    "    #On enlève tous les chemins qui ont été ajoutés à la liste \"a_retirer\"\n",
    "    graph = remove_paths(graph, a_retirer, delete_entry_node, delete_sink_node)\n",
    "    return graph\n",
    "\n",
    "def find_bubbles(graph):\n",
    "    \"\"\"Fonction qui va permettre de trouver les bulles au sein\n",
    "    de l'arbre. Elle retournera les origines et les fins de ces\n",
    "    bulles.\n",
    "    \"\"\"\n",
    "    bulles = []\n",
    "    ensemble_noeuds = list(graph.nodes)\n",
    "    for i in range(len(ensemble_noeuds)):\n",
    "    #On recherche si un noeud a plusieurs successeurs.\n",
    "        if len(list(graph.successors(ensemble_noeuds[i]))) > 1:\n",
    "            debut = ensemble_noeuds[i]\n",
    "            #print(\"le noeud est:{}\".format(ensemble_noeuds[i]))\n",
    "            j = 1\n",
    "            fin = \"\"\n",
    "            #Si oui, on recherche le prochain noeud qui a plusieurs\n",
    "            #prédécesseurs.\n",
    "            #Tant qu'il n'y a qu'un predecesseur et que j est plus petit\n",
    "            #que le nombre de noeuds \"restants\" on test si un noeud a plus\n",
    "            #d'un predecesseur; ce qui permettrait d'encadrer la bulle\n",
    "            fin_trouvee = False\n",
    "            while fin_trouvee == False and j < (len(ensemble_noeuds)-i):\n",
    "                if len(list(graph.predecessors(ensemble_noeuds[i+j]))) > 1:\n",
    "                    #print(j)\n",
    "                    fin = ensemble_noeuds[i+j]\n",
    "                    #print(fin)\n",
    "                    fin_trouvee = True\n",
    "                j += 1\n",
    "            #Si on a récupéré un noeud qui a des successeurs et un noeud\n",
    "            #qui a des prédécesseurs on récupère les coordonnées.\n",
    "            if fin != \"\":\n",
    "                bulles.append([debut, fin])\n",
    "    print(bulles)\n",
    "    #On retourne les coordonnées qui encadrent les bulles.\n",
    "    return bulles\n",
    "\n",
    "\n",
    "\n",
    "def solve_bubble(graph, debut, fin):\n",
    "    \"\"\"Fonction permettant de nettoyer le graph, \n",
    "    en prenant un noeud ancêtre et un noeud descendant.\n",
    "    \"\"\"\n",
    "    ensemble_chemins = []\n",
    "    for path in nx.all_simple_paths(graph,    source=debut, target=fin):\n",
    "        ensemble_chemins.append(path)\n",
    "    print(ensemble_chemins)\n",
    "    if len(ensemble_chemins) >= 2 and type(ensemble_chemins[1]) is list:\n",
    "        poids_moyen = []\n",
    "        ensemble_longueurs = []\n",
    "        for chemin in ensemble_chemins:\n",
    "            poids_moyen.append(path_average_weight(graph, chemin))\n",
    "            ensemble_longueurs.append(len(chemin))\n",
    "        print(poids_moyen)\n",
    "        graph = select_best_path(graph, ensemble_chemins,ensemble_longueurs, poids_moyen, delete_entry_node=False, delete_sink_node=False)\n",
    "    return graph\n",
    "\n",
    "def simplify_bubbles(graph):\n",
    "    \"\"\"Fonction permettant de nettoyer le graph en détectant tous les chemins possible \n",
    "    entre un noeud ancêtre et un noeud descendant.\n",
    "    \"\"\"\n",
    "    liste_bulles = find_bubbles(graph)\n",
    "    for bulle in liste_bulles:\n",
    "        if bulle[0] in graph.nodes and bulle[1] in graph.nodes:\n",
    "            graph = solve_bubble(graph, bulle[0], bulle[1])\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "def solve_entry_tips(graph, entrees):\n",
    "    \"\"\"Fonction qui permet d'enlever les entrées indésirables.\"\"\"\n",
    "    print(entrees)\n",
    "    bornes_initiales = []\n",
    "    #On cherche les noeuds avec des intersections en partant du début\n",
    "    for noeuds_entree in entrees:\n",
    "        ensemble_noeuds = list(graph.nodes)\n",
    "        fin = \"\"\n",
    "        for i in range(len(ensemble_noeuds)):\n",
    "            if len(list(graph.predecessors(ensemble_noeuds[i]))) > 1:\n",
    "                fin = ensemble_noeuds[i]\n",
    "        if fin != \"\":\n",
    "            bornes_initiales.append([noeuds_entree, fin])\n",
    "    print(bornes_initiales)\n",
    "    #Définitions des chemins et valeurs associées\n",
    "    ensemble_chemins = []\n",
    "    poids_moyen = []\n",
    "    ensemble_longueurs = []\n",
    "    for borne in bornes_initiales:\n",
    "        for path in nx.all_simple_paths(graph,\\\n",
    "                source=borne[0], target=borne[1]):\n",
    "            ensemble_chemins.append(path)\n",
    "            poids_moyen.append(path_average_weight(graph, path))\n",
    "            ensemble_longueurs.append(len(path))\n",
    "    #Nettoyage du graph\n",
    "    graph = select_best_path(graph, ensemble_chemins,\\\n",
    "    ensemble_longueurs, poids_moyen, delete_entry_node=True,\\\n",
    "    delete_sink_node=False)\n",
    "    return graph\n",
    "\n",
    "def solve_out_tips(graph, sorties):\n",
    "    \"\"\"Fonction qui permet d'enlever les entrées indésirables\"\"\"\n",
    "    #établissement des bornes de chemins de sortie.\n",
    "    bornes_initiales = []\n",
    "    for noeuds_sortie in sorties:\n",
    "        ensemble_noeuds = list(graph.nodes)\n",
    "        debut = \"\"\n",
    "        for i in range(len(ensemble_noeuds)):\n",
    "            if len(list(graph.successors(ensemble_noeuds[i]))) > 1:\n",
    "                debut = ensemble_noeuds[i]\n",
    "        if debut != \"\":\n",
    "            bornes_initiales.append([debut, noeuds_sortie])\n",
    "    #Définitions des chemins et valeurs associées\n",
    "    ensemble_chemins = []\n",
    "    poids_moyen = []\n",
    "    ensemble_longueurs = []\n",
    "    for borne in bornes_initiales:\n",
    "        for path in nx.all_simple_paths(graph,\\\n",
    "                source=borne[0], target=borne[1]):\n",
    "            ensemble_chemins.append(path)\n",
    "            poids_moyen.append(path_average_weight(graph, path))\n",
    "            ensemble_longueurs.append(len(path))\n",
    "    #Nettoyage du graph\n",
    "    graph = select_best_path(graph, ensemble_chemins,\\\n",
    "    ensemble_longueurs, poids_moyen, delete_entry_node=False,\\\n",
    "    delete_sink_node=True)\n",
    "    return graph\n",
    "\n",
    "def main() : \n",
    "    \n",
    "    args = get_arguments()\n",
    "    \n",
    "    \n",
    "    #fichier_fastq = read_fastq(\"..\\data\\eva71_plus_perfect.fq.\")\n",
    "    #taille_k=21\n",
    "\n",
    "\n",
    "    liste_reads = []\n",
    "    for sequence in fastq_file:\n",
    "        liste_reads.append(sequence)\n",
    "    #print (liste_reads)\n",
    "\n",
    "    liste_kmers = []\n",
    "    for read in liste_reads:\n",
    "        for kmers in cut_kmer(read, taille_k):\n",
    "            liste_kmers.append(kmers)\n",
    "    #print(liste_kmers)\n",
    "    occurrence_kmers = build_kmer_dict(fastq_file, taille_k)\n",
    "    graph = build_graph(occurrence_kmers)\n",
    "    #print(occurrence_kmers)\n",
    "\n",
    "\n",
    "\n",
    "    debuts = get_starting_nodes(graph)\n",
    "    fins = get_sink_nodes(graph)\n",
    "    liste_contigs = get_contigs(graph, debuts, fins)\n",
    "\n",
    "    graph = simplify_bubbles(graph)\n",
    "    noeuds_entree = get_starting_nodes(graph)\n",
    "    while len(noeuds_entree) > 1:\n",
    "        graph = solve_entry_tips(graph, noeuds_entree)\n",
    "        noeuds_entree = get_starting_nodes(graph)\n",
    "    noeuds_entree = get_starting_nodes(graph)\n",
    "\n",
    "    noeuds_terminaux = get_sink_nodes(graph)\n",
    "    while len(noeuds_terminaux) > 1:\n",
    "        graph = solve_out_tips(graph, noeuds_terminaux)\n",
    "        noeuds_terminaux = get_sink_nodes(graph)\n",
    "    noeuds_terminaux = get_sink_nodes(graph)\n",
    "\n",
    "    graph = simplify_bubbles(graph)\n",
    "\n",
    "    final_contig = get_contigs(graph, noeuds_entree, noeuds_terminaux)\n",
    "    print(\"\\n\\n\\nOn obtient {} noeuds d'entrée.\".format(len(noeuds_entree)))\n",
    "    print(\"On obtient {} noeuds de sortie.\".format(len(noeuds_terminaux)))\n",
    "    print(\"Ce qui nous donne {} contigs généré(s).\".format(len(final_contig))) \n",
    "\n",
    "    print(final_contig)\n",
    "    nx.draw(graph)\n",
    "    save_contigs(final_contig, \"Final.fna\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
