{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae4ed5f63a93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "import scipy\n",
    "import os\n",
    "import statistics\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "def read_fastq(fichier_fastq):\n",
    "    with open(fichier_fastq,\"r\") as fastq:\n",
    "        for line in enumerate(fastq):\n",
    "            yield next(fastq)[:-1]\n",
    "            next(fastq)\n",
    "            next(fastq)\n",
    "            \n",
    "\n",
    "\n",
    "def cut_kmer(seq, taille_k):\n",
    "    #On génère des k-mers de taille désirée à partir d'un read .\n",
    "    for i in range(len(seq)-taille_k+1):\n",
    "        yield seq[i:i+taille_k]\n",
    "        \n",
    "if __name__==\"__main__\" :\n",
    "    for i in read_fastq(\"data\\eva71_hundred_reads.fq.\"):\n",
    "        print(i)\n",
    "        for j in cut_kmer(i,taille_k):\n",
    "            print(j,end='')\n",
    "        break\n",
    "        \n",
    "def build_kmer_dict(fichier_fastq,taille_k):\n",
    "    \"\"\"Calcule des occurrences des Kmers dans les reads issus du fastq.\n",
    "    \"\"\"\n",
    "    liste_reads = []\n",
    "    for sequence in fichier_fastq:\n",
    "        liste_reads.append(sequence)\n",
    "    occurrence_kmers = {}\n",
    "    for read in liste_reads:\n",
    "        for kmer in cut_kmer(read, taille_k):\n",
    "            if kmer in occurrence_kmers.keys():\n",
    "                occurrence_kmers[kmer] += 1\n",
    "            else:\n",
    "                occurrence_kmers[kmer] = 1\n",
    "    return occurrence_kmers\n",
    "\n",
    "\n",
    "\n",
    "def build_graph(dict_kmers):\n",
    "    \"\"\"On créé un premier digraph en prenant en compte tout les kmers générés.\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    for kmer, poids in dict_kmers.items():\n",
    "        graph.add_edge(kmer[:-1], kmer[1:], weight=poids)\n",
    "    nx.draw(graph)\n",
    "    return graph\n",
    "\n",
    "#build_kmer_dict(read_fastq(\"data\\eva71_two_reads.fq.\"), taille_kmer)\n",
    "#graph=build_graph(build_kmer_dict(read_fastq(\"data\\eva71_two_reads.fq.\"), taille_kmer))\n",
    "\n",
    "def get_starting_nodes(graph):\n",
    "    \"\"\"Fonction permettant de définir les noeuds d'entrée.\"\"\"\n",
    "    noeuds_entree = []\n",
    "    for noeud in graph.nodes:\n",
    "        if len(list(graph.predecessors(noeud))) == 0:\n",
    "            noeuds_entree.append(noeud)\n",
    "    return noeuds_entree\n",
    "\n",
    "#noeuds_entree = get_starting_nodes(graph)\n",
    "                                   \n",
    "def get_sink_nodes(graph):\n",
    "    \"\"\"Fonction permettant de définir les noeuds de sortie.\"\"\"\n",
    "    noeuds_sortie = []\n",
    "    for noeud in graph.nodes:\n",
    "        if len(list(graph.successors(noeud))) == 0:\n",
    "            noeuds_sortie.append(noeud)\n",
    "    return noeuds_sortie\n",
    "                                   \n",
    "#noeuds_sortie = get_sink_nodes(graph)\n",
    "                                   \n",
    "def get_contigs(graph, start, end):\n",
    "    \"\"\"Fonction permettant de générer une liste de tuples contenant les contigs avec leur taille.\n",
    "    \"\"\"\n",
    "    contigs = []\n",
    "    for noeud_depart in start:\n",
    "        for noeud_fin in end:\n",
    "            for path in nx.all_simple_paths(graph,source=noeud_depart, target=noeud_fin):\n",
    "                prep_contig = path\n",
    "                contig_ecrit = prep_contig[0]\n",
    "                for i in range(1, len(prep_contig)):\n",
    "                    contig_ecrit += prep_contig[i][-1:]\n",
    "                contigs.append((contig_ecrit, len(contig_ecrit)))\n",
    "    return contigs\n",
    "\n",
    "\n",
    "print(len(get_contigs(graph,noeuds_entree,noeuds_sortie)))\n",
    "\n",
    "def fill(text, width=80):\n",
    "    \"\"\"Split text with a line return to respect fasta format\"\"\"\n",
    "    return os.linesep.join(text[i:i+width] for i in range(0, len(text), width))\n",
    "\n",
    "def save_contigs(liste_contigs, nom_fichier):\n",
    "    \"\"\"Cette fonction permet de sauvegarder les contigs dans un fichier FASTA\n",
    "    \"\"\"\n",
    "    with open(nom_fichier, \"w\") as fichier_sortie:\n",
    "        numero = 0\n",
    "        for contigs in liste_contigs:\n",
    "            fichier_sortie.write(\">contig_{0} len={1}\\n\".format(numero, contigs[1]))\n",
    "            fichier_sortie.write(\"{0}\\n\".format(fill(contigs[0])))\n",
    "            numero += 1\n",
    "\n",
    "save_contigs(get_contigs(graph,noeuds_entree,noeuds_sortie),\"Contigs.fna\")\n",
    "\n",
    "def std(liste_valeurs):\n",
    "    \"\"\"Calcul l'écart-type de la liste de valeurs\"\"\"\n",
    "    return statistics.stdev(liste_valeurs)\n",
    "\n",
    "\n",
    "def path_average_weight(graph, chemin):\n",
    "    \"\"\"Cette fonction retourne le poids moyen d'un chemin\n",
    "    \"\"\"\n",
    "    poids = 0\n",
    "    nbre_edges = 0\n",
    "    edges = graph.subgraph(chemin).edges(data=True)\n",
    "    #On va récupérer les poids de chaque lien.\n",
    "    for u_value, v_value, e_value in edges:\n",
    "        poids += e_value['weight']\n",
    "        nbre_edges += 1\n",
    "    poids = poids/nbre_edges\n",
    "    return poids\n",
    "\n",
    "def remove_paths(graph, liste_chemins, delete_entry_node=False, delete_sink_node=False):\n",
    "    \"\"\"Fonction permettant de verifier si on enlève ou non les noeuds de départe et de fin pour chaque chemin\n",
    "    Et retourne un graph nettoyé des chemins indésirables\n",
    "    \"\"\"\n",
    "    for chemin in liste_chemins:\n",
    "        if delete_entry_node == False and delete_sink_node == False:\n",
    "            for noeud in chemin[1:-1]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node and delete_sink_node == False:\n",
    "            for noeud in chemin[:-1]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node == False and delete_sink_node:\n",
    "            for noeud in chemin[1:]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node and delete_sink_node:\n",
    "            for noeud in chemin[:]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "    return graph\n",
    "\n",
    "def select_best_path(graph, ensemble_chemins, ensemble_longueurs,\\\n",
    "poids_moyen, delete_entry_node=False, delete_sink_node=False):\n",
    "    \"\"\"Fonction qui va permettre d'identifier le meilleur chemin selon 3 critères :\n",
    "    - poids le plus élevé\n",
    "    - les chemins les plus long\n",
    "    - on tire une au hasard\n",
    "    Les chemins non conservés sont envoyés à la fonction remove_paths.\n",
    "    \"\"\"\n",
    "    a_retirer = []\n",
    "    taille_max = max(poids_moyen)\n",
    "    chemin_fort_poids = []\n",
    "    #On recherche les chemins qui ont un poids correspondant\n",
    "    #au poids maximum (de préférence un seul ...)\n",
    "    for i in range(len(ensemble_chemins)):\n",
    "        if poids_moyen[i] == taille_max:\n",
    "            chemin_fort_poids.append(ensemble_chemins[i])\n",
    "    #On récupère les chemins à conserver puis on ajoute\n",
    "    #les autres à la liste \"a_retirer\"\n",
    "    for chemin in chemin_fort_poids:\n",
    "        ensemble_chemins.remove(chemin)\n",
    "    a_retirer = ensemble_chemins + a_retirer\n",
    "    #S'il y a plus qu'un chemin qui a le poids maximum on regarde\n",
    "    #la taille de ceux le poids maximum.\n",
    "    if len(chemin_fort_poids) > 1:\n",
    "        longueur_max = max(ensemble_longueurs)\n",
    "        grands_chemins = []\n",
    "        for i in range(len(chemin_fort_poids)):\n",
    "            if ensemble_longueurs[i] == longueur_max:\n",
    "                grands_chemins.append(chemin_fort_poids[i])\n",
    "        #On récupère les chemins à conserver puis on ajoute\n",
    "        #les autres à la liste \"a_retirer\"\n",
    "        for chemin in grands_chemins:\n",
    "            chemin_fort_poids.remove(chemin)\n",
    "        a_retirer = chemin_fort_poids + a_retirer\n",
    "        #S'il y a plusieurs chemins qui ont la taille maximum\n",
    "        #on tire un chemin au hasard parmis ceux ayant le poids\n",
    "        #maximum et la plus grande taille.\n",
    "        if len(grands_chemins) > 1:\n",
    "            random.seed(9001)\n",
    "            choix = random.randint(0, len(grands_chemins))\n",
    "            print(choix)\n",
    "            choix_chemin = grands_chemins[choix]\n",
    "            #On récupère les chemins à conserver puis on ajoute\n",
    "            #les autres à la liste \"a_retirer\"\n",
    "            grands_chemins.remove(choix_chemin[0])\n",
    "            a_retirer = grands_chemins + a_retirer\n",
    "    #On enlève tous les chemins qui ont été ajoutés à la liste \"a_retirer\"\n",
    "    graph = remove_paths(graph, a_retirer, delete_entry_node, delete_sink_node)\n",
    "    return graph\n",
    "\n",
    "def find_bubbles(graph):\n",
    "    \"\"\"Fonction qui va permettre de trouver les bulles au sein\n",
    "    de l'arbre. Elle retournera les origines et les fins de ces\n",
    "    bulles.\n",
    "    \"\"\"\n",
    "    bulles = []\n",
    "    ensemble_noeuds = list(graph.nodes)\n",
    "    for i in range(len(ensemble_noeuds)):\n",
    "    #On recherche si un noeud a plusieurs successeurs.\n",
    "        if len(list(graph.successors(ensemble_noeuds[i]))) > 1:\n",
    "            debut = ensemble_noeuds[i]\n",
    "            #print(\"le noeud est:{}\".format(ensemble_noeuds[i]))\n",
    "            j = 1\n",
    "            fin = \"\"\n",
    "            #Si oui, on recherche le prochain noeud qui a plusieurs\n",
    "            #prédécesseurs.\n",
    "            #Tant qu'il n'y a qu'un predecesseur et que j est plus petit\n",
    "            #que le nombre de noeuds \"restants\" on test si un noeud a plus\n",
    "            #d'un predecesseur; ce qui permettrait d'encadrer la bulle\n",
    "            fin_trouvee = False\n",
    "            while fin_trouvee == False and j < (len(ensemble_noeuds)-i):\n",
    "                if len(list(graph.predecessors(ensemble_noeuds[i+j]))) > 1:\n",
    "                    #print(j)\n",
    "                    fin = ensemble_noeuds[i+j]\n",
    "                    #print(fin)\n",
    "                    fin_trouvee = True\n",
    "                j += 1\n",
    "            #Si on a récupéré un noeud qui a des successeurs et un noeud\n",
    "            #qui a des prédécesseurs on récupère les coordonnées.\n",
    "            if fin != \"\":\n",
    "                bulles.append([debut, fin])\n",
    "    print(bulles)\n",
    "    #On retourne les coordonnées qui encadrent les bulles.\n",
    "    return bulles\n",
    "\n",
    "\n",
    "\n",
    "def solve_bubble(graph, debut, fin):\n",
    "    \"\"\"Fonction permettant de nettoyer le graph, \n",
    "    en prenant un noeud ancêtre et un noeud descendant.\n",
    "    \"\"\"\n",
    "    ensemble_chemins = []\n",
    "    for path in nx.all_simple_paths(graph,\\\n",
    "    source=debut, target=fin):\n",
    "        ensemble_chemins.append(path)\n",
    "    print(ensemble_chemins)\n",
    "    if len(ensemble_chemins) >= 2 and type(ensemble_chemins[1]) is list:\n",
    "        poids_moyen = []\n",
    "        ensemble_longueurs = []\n",
    "        for chemin in ensemble_chemins:\n",
    "            poids_moyen.append(path_average_weight(graph, chemin))\n",
    "            ensemble_longueurs.append(len(chemin))\n",
    "        print(poids_moyen)\n",
    "        graph = select_best_path(graph, ensemble_chemins,\\\n",
    "        ensemble_longueurs, poids_moyen, delete_entry_node=False,\\\n",
    "        delete_sink_node=False)\n",
    "    return graph\n",
    "\n",
    "def simplify_bubbles(graph):\n",
    "    \"\"\"Fonction permettant de nettoyer le graph en détectant tous les chemins possible \n",
    "    entre un noeud ancêtre et un noeud descendant.\n",
    "    \"\"\"\n",
    "    liste_bulles = find_bubbles(graph)\n",
    "    for bulle in liste_bulles:\n",
    "        if bulle[0] in graph.nodes and bulle[1] in graph.nodes:\n",
    "            graph = solve_bubble(graph, bulle[0], bulle[1])\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "fichier_fastq = read_fastq(\"data\\eva71_hundred_reads.fq.\")\n",
    "taille_k=21\n",
    "   \n",
    "def main():\n",
    "    liste_reads = []\n",
    "    for sequence in fichier_fastq:\n",
    "        liste_reads.append(sequence)\n",
    "    #print (liste_reads)\n",
    "\n",
    "    liste_kmers = []\n",
    "    for read in liste_reads:\n",
    "        for kmers in cut_kmer(read, taille_k):\n",
    "            liste_kmers.append(kmers)\n",
    "    #print(liste_kmers)\n",
    "    occurrence_kmers = build_kmer_dict(fichier_fastq, taille_k)\n",
    "    #print(occurrence_kmers)\n",
    "\n",
    "\n",
    "\n",
    "    debuts = get_starting_nodes(graph)\n",
    "    fins = get_sink_nodes(graph)\n",
    "    liste_contigs = get_contigs(graph, debuts, fins)\n",
    "\n",
    "    graph = simplify_bubbles(graph)\n",
    "    nx.draw(graph) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4b540acc2bf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstatistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "import scipy\n",
    "import os\n",
    "import statistics\n",
    "import argparse\n",
    "taille_k=21\n",
    "\n",
    "def read_fastq(fichier_fastq):\n",
    "    with open(fichier_fastq,\"r\") as fastq:\n",
    "        for line in enumerate(fastq):\n",
    "            yield next(fastq)[:-1]\n",
    "            next(fastq)\n",
    "            next(fastq)\n",
    "            \n",
    "\n",
    "\n",
    "def cut_kmer(seq, taille_k):\n",
    "    #On génère des k-mers de taille désirée à partir d'un read .\n",
    "    for i in range(len(seq)-taille_k+1):\n",
    "        yield seq[i:i+taille_k]\n",
    "        \n",
    "if __name__==\"__main__\" :\n",
    "    for i in read_fastq(\"data\\eva71_hundred_reads.fq.\"):\n",
    "        print(i)\n",
    "        for j in cut_kmer(i,taille_k):\n",
    "            print(j,end='')\n",
    "        break\n",
    "        \n",
    "def build_kmer_dict(fichier_fastq,taille_k):\n",
    "    \"\"\"Calcule des occurrences des Kmers dans les reads issus du fastq.\n",
    "    \"\"\"\n",
    "    liste_reads = []\n",
    "    for sequence in fichier_fastq:\n",
    "        liste_reads.append(sequence)\n",
    "    occurrence_kmers = {}\n",
    "    for read in liste_reads:\n",
    "        for kmer in cut_kmer(read, taille_k):\n",
    "            if kmer in occurrence_kmers.keys():\n",
    "                occurrence_kmers[kmer] += 1\n",
    "            else:\n",
    "                occurrence_kmers[kmer] = 1\n",
    "    return occurrence_kmers\n",
    "\n",
    "\n",
    "\n",
    "def build_graph(dict_kmers):\n",
    "    \"\"\"On créé un premier digraph en prenant en compte tout les kmers générés.\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    for kmer, poids in dict_kmers.items():\n",
    "        graph.add_edge(kmer[:-1], kmer[1:], weight=poids)\n",
    "    nx.draw(graph)\n",
    "    return graph\n",
    "\n",
    "#build_kmer_dict(read_fastq(\"data\\eva71_two_reads.fq.\"), taille_kmer)\n",
    "graph=build_graph(build_kmer_dict(read_fastq(\"data\\eva71_two_reads.fq.\"), taille_k))\n",
    "\n",
    "def get_starting_nodes(graph):\n",
    "    \"\"\"Fonction permettant de définir les noeuds d'entrée.\"\"\"\n",
    "    noeuds_entree = []\n",
    "    for noeud in graph.nodes:\n",
    "        if len(list(graph.predecessors(noeud))) == 0:\n",
    "            noeuds_entree.append(noeud)\n",
    "    return noeuds_entree\n",
    "\n",
    "#noeuds_entree = get_starting_nodes(graph)\n",
    "                                   \n",
    "def get_sink_nodes(graph):\n",
    "    \"\"\"Fonction permettant de définir les noeuds de sortie.\"\"\"\n",
    "    noeuds_sortie = []\n",
    "    for noeud in graph.nodes:\n",
    "        if len(list(graph.successors(noeud))) == 0:\n",
    "            noeuds_sortie.append(noeud)\n",
    "    return noeuds_sortie\n",
    "                                   \n",
    "#noeuds_sortie = get_sink_nodes(graph)\n",
    "                                   \n",
    "def get_contigs(graph, start, end):\n",
    "    \"\"\"Fonction permettant de générer une liste de tuples contenant les contigs avec leur taille.\n",
    "    \"\"\"\n",
    "    contigs = []\n",
    "    for noeud_depart in start:\n",
    "        for noeud_fin in end:\n",
    "            for path in nx.all_simple_paths(graph,source=noeud_depart, target=noeud_fin):\n",
    "                prep_contig = path\n",
    "                contig_ecrit = prep_contig[0]\n",
    "                for i in range(1, len(prep_contig)):\n",
    "                    contig_ecrit += prep_contig[i][-1:]\n",
    "                contigs.append((contig_ecrit, len(contig_ecrit)))\n",
    "    return contigs\n",
    "\n",
    "\n",
    "def fill(text, width=80):\n",
    "    \"\"\"Split text with a line return to respect fasta format\"\"\"\n",
    "    return os.linesep.join(text[i:i+width] for i in range(0, len(text), width))\n",
    "\n",
    "def save_contigs(liste_contigs, nom_fichier):\n",
    "    \"\"\"Cette fonction permet de sauvegarder les contigs dans un fichier FASTA\n",
    "    \"\"\"\n",
    "    with open(nom_fichier, \"w\") as fichier_sortie:\n",
    "        numero = 0\n",
    "        for contigs in liste_contigs:\n",
    "            fichier_sortie.write(\">contig_{0} len={1}\\n\".format(numero, contigs[1]))\n",
    "            fichier_sortie.write(\"{0}\\n\".format(fill(contigs[0])))\n",
    "            numero += 1\n",
    "\n",
    "    save_contigs(get_contigs(graph,noeuds_entree,noeuds_sortie),\"Contigs.fna\")\n",
    "\n",
    "def std(liste_valeurs):\n",
    "    \"\"\"Calcul l'écart-type de la liste de valeurs\"\"\"\n",
    "    return statistics.stdev(liste_valeurs)\n",
    "\n",
    "\n",
    "def path_average_weight(graph, chemin):\n",
    "    \"\"\"Cette fonction retourne le poids moyen d'un chemin\n",
    "    \"\"\"\n",
    "    poids = 0\n",
    "    nbre_edges = 0\n",
    "    edges = graph.subgraph(chemin).edges(data=True)\n",
    "    #On va récupérer les poids de chaque lien.\n",
    "    for u_value, v_value, e_value in edges:\n",
    "        poids += e_value['weight']\n",
    "        nbre_edges += 1\n",
    "    poids = poids/nbre_edges\n",
    "    return poids\n",
    "\n",
    "def remove_paths(graph, liste_chemins, delete_entry_node=False, delete_sink_node=False):\n",
    "    \"\"\"Fonction permettant de verifier si on enlève ou non les noeuds de départe et de fin pour chaque chemin\n",
    "    Et retourne un graph nettoyé des chemins indésirables\n",
    "    \"\"\"\n",
    "    for chemin in liste_chemins:\n",
    "        if delete_entry_node == False and delete_sink_node == False:\n",
    "            for noeud in chemin[1:-1]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node and delete_sink_node == False:\n",
    "            for noeud in chemin[:-1]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node == False and delete_sink_node:\n",
    "            for noeud in chemin[1:]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "        elif delete_entry_node and delete_sink_node:\n",
    "            for noeud in chemin[:]:\n",
    "                if noeud in graph.nodes:\n",
    "                    graph.remove_node(noeud)\n",
    "    return graph\n",
    "\n",
    "def select_best_path(graph, ensemble_chemins, ensemble_longueurs,poids_moyen, delete_entry_node=False, delete_sink_node=False):\n",
    "    \"\"\"Fonction qui va permettre d'identifier le meilleur chemin selon 3 critères :\n",
    "    - poids le plus élevé\n",
    "    - les chemins les plus long\n",
    "    - on tire une au hasard\n",
    "    Les chemins non conservés sont envoyés à la fonction remove_paths.\n",
    "    \"\"\"\n",
    "    a_retirer = []\n",
    "    taille_max = max(poids_moyen)\n",
    "    chemin_fort_poids = []\n",
    "    #On recherche les chemins qui ont un poids correspondant\n",
    "    #au poids maximum (de préférence un seul ...)\n",
    "    for i in range(len(ensemble_chemins)):\n",
    "        if poids_moyen[i] == taille_max:\n",
    "            chemin_fort_poids.append(ensemble_chemins[i])\n",
    "    #On récupère les chemins à conserver puis on ajoute\n",
    "    #les autres à la liste \"a_retirer\"\n",
    "    for chemin in chemin_fort_poids:\n",
    "        ensemble_chemins.remove(chemin)\n",
    "    a_retirer = ensemble_chemins + a_retirer\n",
    "    #S'il y a plus qu'un chemin qui a le poids maximum on regarde\n",
    "    #la taille de ceux le poids maximum.\n",
    "    if len(chemin_fort_poids) > 1:\n",
    "        longueur_max = max(ensemble_longueurs)\n",
    "        grands_chemins = []\n",
    "        for i in range(len(chemin_fort_poids)):\n",
    "            if ensemble_longueurs[i] == longueur_max:\n",
    "                grands_chemins.append(chemin_fort_poids[i])\n",
    "        #On récupère les chemins à conserver puis on ajoute\n",
    "        #les autres à la liste \"a_retirer\"\n",
    "        for chemin in grands_chemins:\n",
    "            chemin_fort_poids.remove(chemin)\n",
    "        a_retirer = chemin_fort_poids + a_retirer\n",
    "        #S'il y a plusieurs chemins qui ont la taille maximum\n",
    "        #on tire un chemin au hasard parmis ceux ayant le poids\n",
    "        #maximum et la plus grande taille.\n",
    "        if len(grands_chemins) > 1:\n",
    "            random.seed(9001)\n",
    "            choix = random.randint(0, len(grands_chemins))\n",
    "            print(choix)\n",
    "            choix_chemin = grands_chemins[choix]\n",
    "            #On récupère les chemins à conserver puis on ajoute\n",
    "            #les autres à la liste \"a_retirer\"\n",
    "            grands_chemins.remove(choix_chemin[0])\n",
    "            a_retirer = grands_chemins + a_retirer\n",
    "    #On enlève tous les chemins qui ont été ajoutés à la liste \"a_retirer\"\n",
    "    graph = remove_paths(graph, a_retirer, delete_entry_node, delete_sink_node)\n",
    "    return graph\n",
    "\n",
    "def find_bubbles(graph):\n",
    "    \"\"\"Fonction qui va permettre de trouver les bulles au sein\n",
    "    de l'arbre. Elle retournera les origines et les fins de ces\n",
    "    bulles.\n",
    "    \"\"\"\n",
    "    bulles = []\n",
    "    ensemble_noeuds = list(graph.nodes)\n",
    "    for i in range(len(ensemble_noeuds)):\n",
    "    #On recherche si un noeud a plusieurs successeurs.\n",
    "        if len(list(graph.successors(ensemble_noeuds[i]))) > 1:\n",
    "            debut = ensemble_noeuds[i]\n",
    "            #print(\"le noeud est:{}\".format(ensemble_noeuds[i]))\n",
    "            j = 1\n",
    "            fin = \"\"\n",
    "            #Si oui, on recherche le prochain noeud qui a plusieurs\n",
    "            #prédécesseurs.\n",
    "            #Tant qu'il n'y a qu'un predecesseur et que j est plus petit\n",
    "            #que le nombre de noeuds \"restants\" on test si un noeud a plus\n",
    "            #d'un predecesseur; ce qui permettrait d'encadrer la bulle\n",
    "            fin_trouvee = False\n",
    "            while fin_trouvee == False and j < (len(ensemble_noeuds)-i):\n",
    "                if len(list(graph.predecessors(ensemble_noeuds[i+j]))) > 1:\n",
    "                    #print(j)\n",
    "                    fin = ensemble_noeuds[i+j]\n",
    "                    #print(fin)\n",
    "                    fin_trouvee = True\n",
    "                j += 1\n",
    "            #Si on a récupéré un noeud qui a des successeurs et un noeud\n",
    "            #qui a des prédécesseurs on récupère les coordonnées.\n",
    "            if fin != \"\":\n",
    "                bulles.append([debut, fin])\n",
    "    print(bulles)\n",
    "    #On retourne les coordonnées qui encadrent les bulles.\n",
    "    return bulles\n",
    "\n",
    "\n",
    "\n",
    "def solve_bubble(graph, debut, fin):\n",
    "    \"\"\"Fonction permettant de nettoyer le graph, \n",
    "    en prenant un noeud ancêtre et un noeud descendant.\n",
    "    \"\"\"\n",
    "    ensemble_chemins = []\n",
    "    for path in nx.all_simple_paths(graph,    source=debut, target=fin):\n",
    "        ensemble_chemins.append(path)\n",
    "    print(ensemble_chemins)\n",
    "    if len(ensemble_chemins) >= 2 and type(ensemble_chemins[1]) is list:\n",
    "        poids_moyen = []\n",
    "        ensemble_longueurs = []\n",
    "        for chemin in ensemble_chemins:\n",
    "            poids_moyen.append(path_average_weight(graph, chemin))\n",
    "            ensemble_longueurs.append(len(chemin))\n",
    "        print(poids_moyen)\n",
    "        graph = select_best_path(graph, ensemble_chemins,        ensemble_longueurs, poids_moyen, delete_entry_node=False,        delete_sink_node=False)\n",
    "    return graph\n",
    "\n",
    "def simplify_bubbles(graph):\n",
    "    \"\"\"Fonction permettant de nettoyer le graph en détectant tous les chemins possible \n",
    "    entre un noeud ancêtre et un noeud descendant.\n",
    "    \"\"\"\n",
    "    liste_bulles = find_bubbles(graph)\n",
    "    for bulle in liste_bulles:\n",
    "        if bulle[0] in graph.nodes and bulle[1] in graph.nodes:\n",
    "            graph = solve_bubble(graph, bulle[0], bulle[1])\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "def solve_entry_tips():\n",
    "    pass\n",
    "def solve_out_tips():\n",
    "    pass\n",
    "    \n",
    "fichier_fastq = read_fastq(\"data\\eva71_hundred_reads.fq.\")\n",
    "taille_k=21\n",
    "   \n",
    "\n",
    "liste_reads = []\n",
    "for sequence in fichier_fastq:\n",
    "    liste_reads.append(sequence)\n",
    "#print (liste_reads)\n",
    "\n",
    "liste_kmers = []\n",
    "for read in liste_reads:\n",
    "    for kmers in cut_kmer(read, taille_k):\n",
    "        liste_kmers.append(kmers)\n",
    "#print(liste_kmers)\n",
    "occurrence_kmers = build_kmer_dict(fichier_fastq, taille_k)\n",
    "#print(occurrence_kmers)\n",
    "\n",
    "\n",
    "\n",
    "debuts = get_starting_nodes(graph)\n",
    "fins = get_sink_nodes(graph)\n",
    "liste_contigs = get_contigs(graph, debuts, fins)\n",
    "\n",
    "graph = simplify_bubbles(graph)\n",
    "nx.draw(graph) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
